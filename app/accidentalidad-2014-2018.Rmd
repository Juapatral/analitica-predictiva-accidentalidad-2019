---
title: <b><center>Análisis y pronóstico de la información accidentalidad vehicular en el municipio de Medellín para los años 2014 a 2018</center></b>

author: <center>Lina María Grajales Vanegas <br> Juan Camilo Agudelo Marín <br> Jhon Anderson Lonoño Herrera <br> Juan Pablo Trujillo Alviz <br><br> Estudiantes del Posgrado en Analítica <br> Universidad Nacional de Colombia, Medellín</center>

date: "11 de agosto de 2019"

output:
  html_document:
    #toc: true
    #toc_depth: 5
    #toc_float: 
    #  collapsed: true
    #  smooth_scroll: true
    #toc_width: 5
    theme: cerulean
    highlight: default
    df_print: paged
    fig_width: 9
    fig_height: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## **Tabla de contenido**
 
1. [Introducción](#introduccion)

    1.1. [Motivación](#motivacion)
    
    1.2. [Metodología](#metodologia)

2. [Desarrollo](#desarrollo)

    2.1. [Identificación del problema](#identificacion-del-problema)
    
    2.2. [Identificación de los datos](#identificacion-de-los-datos)
    
    2.3. [Descripción de los datos](#descripcion-del-conjunto-de-datos)<br>
    
    2.3.1. [Limpieza y resumen](#limpieza-y-resumen-de-los-datos)<br>
    2.3.2. [Análisis de los datos](#analisis)<br>
    2.3.3. [Tratamiento de datos atípicos](#datos-atipicos-o-nulos)<br>
        
    2.4. [Modelación de los datos](#modelacion-de-los-datos)
    
    2.5. [Evaluación del modelo](#evaluacion-del-modelo)
    
    2.6. [Implementación del modelo](#implementacion)
    
3. [Conclusiones](#conclusiones)

4. [Bibliografía](#bibliografia)


## **1. Introducción**

Cada día se generan cantidades enormes de datos que reposan en los sistemas de información y bases de datos públicas o privadas. Es de interés para los analístas de datos obtener la mayor cantidad de información valiosa y confiable de estos datos, generando valor agregado a las entidades y así incidir en la toma de decisiones para mejorar los procesos internos y, por ende, los resultados económicos y sociales de la entidad. (**FALTA UNA REFERENCIA**)

Por esta razón, los estudiantes de la materia Analítica Predictiva del Posgrado de Analítica de la Universidad Nacional de Colombia tienen como objetivo identificar y dar solución a un problema utilizando las técnicas estadísticas y de ciencia de datos que consideren óptimas. 

### **1.1. Motivación**

La materia de Analítica Predictiva en el Posgrado de Analítica de la Universidad Nacional de Colombia enseña algunas técnicas estadísticas para el pronóstico y clasificación de datos, utilizando los conceptos de la estadística descriptiva y probabilística como cálculo de probabilidades, Teorema de Bayes, medidas de tendencia, funciones de distribuciones de probabilidad, pruebas de hipótesis, entre otros. Algunos de los modelos vistos en clase fueron:

* K vecinos cercanos (kNN)
* Regresión lineal (univariada y multivariada) 
* Regresión Ridge y Lasso (Casos de multicolinealidad de la regresión lineal)
* Regresión logística (logit)
* Bosques aleatorios (Random Forest)
* Árboles de decisión (Decision Tree)
* Validación cruzada (Cross validation)

El objetivo de este trabajo es entrenar un modelo predictivo que permita encontrar solución a un problema propuesto por los estudiantes. Este problema deberá contar con suficiente información para estimar el modelo y este no debe estar sobreentrenado. 

Los entregables del trabajo son:

1. Código de ejecución del modelo. (disponible [aquí](https://google.com.co))
2. Reporte que contenga el entendimiento desarrollado en el trabajo, bibliografía de soporte y la metodología seguida debidamente justificada. (disponible [aquí](https://google.com.co))
3. Aplicativo web que permita visualizar los datos y la predicción del modelo. (disponible [aquí](https://google.com.co)).
4. Video promocional del aplicativo web, explicando su funcionalidad. (disponible [aquí](https://youtube.com)) 

Para este trabajo se decidió utilizar la información anonimizada de los registros del Impuesto de Industria y Comercio entre los años 2013 y 2018, proporcionada por la Alcaldía de Medellín.

### **1.2. Metodología**

Se propone utilizar la metodología [CRISP-DM](https://jdvelasq.github.io/ruta-n-predictiva/_downloads/5731da83c31e211e9b774ae8713246ed/CRISP-DM.pdf) en la que se sigue un flujo de trabajo para la identificación del problema y la propuesta, evaluación e implementación de la solución. Los pasos de la metodología *CRISP-DM* son los siguientes:

1. Identificación del problema del negocio (Va en desarrollo, **QUIEN**)

2. Identificación del problema de datos (Va en desarrollo, **QUIEN**)

3. Preparación de los datos (Estadística descriptiva, **Lina JP**)

4. Modelación (Elegir modelo, programar, **QUIEN**)

5. Evaluación (Verificación del modelo, aplicabilidad, **QUIEN**)

6. Implementación (Aplicativo web, video. **Jhon, JC**)

[Regresar](#tabla-de-contenido)

## **2. Desarrollo**

### **2.1. Identificación del problema**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.2. Identificación de los datos**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.3. Descripción del conjunto de datos**

Para el análisis de la información se utilizará el dialecto *Tidyverse* y los paquetes *data.table*, *plotly*, *rmarkdown*, *shiny* y **FALTA PAQUETES MODELO**.

```{r Paquetes, message=FALSE, warning=FALSE}
# se instalan los paquetes necesarios

#install.packages("tidyverse")    # dialecto de ciencia de datos
#install.packages("data.table")   # manejo de tablas
#install.packages("plotly")       # graficas semi-dinamicas
#install.packages("rmarkdown")    # utilizar rmarkdown
#install.packages("shiny")        # tableros de control dinamicos
#install.packages("prettydoc")    # dar formato a rmarkdown
```

**FALTA**

[Regresar](#tabla-de-contenido)

#### **2.3.2. Análisis**

**FALTA**

Unificar datos

```{r lectura_consolidado, message=FALSE, warning=FALSE}
# cargar librerias
library(data.table)
library(purrr)
library(dplyr)

# lista archivos
lista <- list.files(pattern = "*.csv", include.dirs = T, recursive = T)

# leer todos los archivos
lista_df <- map(lista, fread, sep = ",", encoding = "UTF-8", colClasses = "c")

# agregar archivos del 2014 a 2018
acc <- bind_rows(lista_df)

# ver cabecera del archivo
head(acc)
```

[Regresar](#tabla-de-contenido)

#### **2.3.3. Datos atípicos o nulos**

**FALTA**


[Regresar](#tabla-de-contenido)

### **2.4. Modelación de los datos**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.5. Evaluación del modelo**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.6. Implementación**

**FALTA**

[Regresar](#tabla-de-contenido)

## **3. Conclusiones**

**FALTA**

[Regresar](#tabla-de-contenido)

## **4. Bibliografía**

**FALTA**

**R Markdown**

[Infografía de *Rmarkdown*](https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf)

[API de *Rmarkdown*](https://bookdown.org/yihui/rmarkdown/)

---

**Plotly**

[API de *Plotly*](https://plot.ly/r/reference/)

---

**Demás**

[link aquí](https://wikipedia.com)

---

[Regresar](#tabla-de-contenido)
