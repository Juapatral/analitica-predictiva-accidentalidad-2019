---
title: <b><center>Análisis y pronóstico de la información accidentalidad vehicular en el municipio de Medellín para los años 2014 a 2018</center></b>

author: <center>Lina María Grajales Vanegas <br> Juan Camilo Agudelo Marín <br> Jhon Anderson Lonoño Herrera <br> Juan Pablo Trujillo Alviz <br><br> Estudiantes del Posgrado en Analítica <br> Universidad Nacional de Colombia, Medellín</center>

date: "11 de agosto de 2019"

output:
  html_document:
    #toc: true
    #toc_depth: 5
    #toc_float: 
    #  collapsed: true
    #  smooth_scroll: true
    #toc_width: 5
    theme: cerulean
    highlight: default
    df_print: paged
    fig_width: 9
    fig_height: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## **Tabla de contenido**
 
1. [Introducción](#introduccion)

    1.1. [Motivación](#motivacion)
    
    1.2. [Metodología](#metodologia)

2. [Desarrollo](#desarrollo)

    2.1. [Identificación del problema](#identificacion-del-problema)
    
    2.2. [Identificación de los datos](#identificacion-de-los-datos)
    
    2.3. [Descripción de los datos](#descripcion-del-conjunto-de-datos)<br>
    
    2.3.1. [Limpieza y resumen](#limpieza-y-resumen-de-los-datos)<br>
    2.3.2. [Análisis de los datos](#analisis)<br>
    2.3.3. [Tratamiento de datos atípicos](#datos-atipicos-o-nulos)<br>
        
    2.4. [Modelación de los datos](#modelacion-de-los-datos)
    
    2.5. [Evaluación del modelo](#evaluacion-del-modelo)
    
    2.6. [Implementación del modelo](#implementacion)
    
3. [Conclusiones](#conclusiones)

4. [Bibliografía](#bibliografia)


## **1. Introducción**

Cada día se generan cantidades enormes de datos que reposan en los sistemas de información y bases de datos públicas o privadas. Es de interés para los analístas de datos obtener la mayor cantidad de información valiosa y confiable de estos datos, generando valor agregado a las entidades y así incidir en la toma de decisiones para mejorar los procesos internos y, por ende, los resultados económicos y sociales de la entidad. (**FALTA UNA REFERENCIA**)

Por esta razón, los estudiantes de la materia Analítica Predictiva del Posgrado de Analítica de la Universidad Nacional de Colombia tienen como objetivo identificar y dar solución a un problema utilizando las técnicas estadísticas y de ciencia de datos que consideren óptimas. 

### **1.1. Motivación**

La materia de Analítica Predictiva en el Posgrado de Analítica de la Universidad Nacional de Colombia enseña algunas técnicas estadísticas para el pronóstico y clasificación de datos, utilizando los conceptos de la estadística descriptiva y probabilística como cálculo de probabilidades, Teorema de Bayes, medidas de tendencia, funciones de distribuciones de probabilidad, pruebas de hipótesis, entre otros. Algunos de los modelos vistos en clase fueron:

* K vecinos cercanos (kNN)
* Regresión lineal (univariada y multivariada) 
* Regresión Ridge y Lasso (Casos de multicolinealidad de la regresión lineal)
* Regresión logística (logit)
* Bosques aleatorios (Random Forest)
* Árboles de decisión (Decision Tree)
* Validación cruzada (Cross validation)

El objetivo de este trabajo es entrenar un modelo predictivo que permita encontrar solución a un problema propuesto por los estudiantes. Este problema deberá contar con suficiente información para estimar el modelo y este no debe estar sobreentrenado. 

Los entregables del trabajo son:

1. Código de ejecución del modelo. (disponible [aquí](https://google.com.co))
2. Reporte que contenga el entendimiento desarrollado en el trabajo, bibliografía de soporte y la metodología seguida debidamente justificada. (disponible [aquí](https://google.com.co))
3. Aplicativo web que permita visualizar los datos y la predicción del modelo. (disponible [aquí](https://google.com.co)).
4. Video promocional del aplicativo web, explicando su funcionalidad. (disponible [aquí](https://youtube.com)) 

Para este trabajo se decidió utilizar la información anonimizada de los registros del Impuesto de Industria y Comercio entre los años 2013 y 2018, proporcionada por la Alcaldía de Medellín.

### **1.2. Metodología**

Se propone utilizar la metodología [CRISP-DM](https://jdvelasq.github.io/ruta-n-predictiva/_downloads/5731da83c31e211e9b774ae8713246ed/CRISP-DM.pdf) en la que se sigue un flujo de trabajo para la identificación del problema y la propuesta, evaluación e implementación de la solución. Los pasos de la metodología *CRISP-DM* son los siguientes:

1. Identificación del problema del negocio (Va en desarrollo, **QUIEN**)

2. Identificación del problema de datos (Va en desarrollo, **QUIEN**)

3. Preparación de los datos (Estadística descriptiva, **Lina JP**)

4. Modelación (Elegir modelo, programar, **QUIEN**)

5. Evaluación (Verificación del modelo, aplicabilidad, **QUIEN**)

6. Implementación (Aplicativo web, video. **Jhon, JC**)

[Regresar](#tabla-de-contenido)

## **2. Desarrollo**

### **2.1. Identificación del problema**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.2. Identificación de los datos**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.3. Descripción del conjunto de datos**

Para el análisis de la información se utilizará el dialecto *Tidyverse* y los paquetes *data.table*, *plotly*, *rmarkdown*, *shiny* y **FALTA PAQUETES MODELO**.

```{r Paquetes, message=FALSE, warning=FALSE}
# se instalan los paquetes necesarios

#install.packages("tidyverse")    # dialecto de ciencia de datos
#install.packages("data.table")   # manejo de tablas
#install.packages("plotly")       # graficas semi-dinamicas
#install.packages("rmarkdown")    # utilizar rmarkdown
#install.packages("shiny")        # tableros de control dinamicos
#install.packages("prettydoc")    # dar formato a rmarkdown
```

**FALTA**

[Regresar](#tabla-de-contenido)

#### **2.3.2. Análisis**

**FALTA**

Unificar datos

```{r lectura_consolidado, message=FALSE, warning=FALSE}
# cargar librerias
library(data.table)
library(purrr)
library(dplyr)
library(plotly)
library(tidyr)

# lista archivos
lista <- list.files(pattern = "*.csv", include.dirs = T, recursive = T)

# leer todos los archivos
lista_df <- map(lista, fread, sep = ",", encoding = "UTF-8", colClasses = "c")

# agregar archivos del 2014 a 2018
acc <- bind_rows(lista_df)

# ver cabecera del archivo
head(acc)
```
 

# Contar número de accidentes por comuna
```{r}
acc_comuna <- acc %>% 
              group_by(COMUNA) %>% 
              summarize(total_registros = n())
head(acc_comuna)
```
# Accidentes por mes 
```{r}
acc_mes <- acc %>% 
              group_by(MES) %>% 
              summarize(total_registros = n())
head(acc_mes)
```

```{r}
ggplot(data=acc_mes, aes(x=MES, y=total_registros)) + 
    geom_bar(stat="identity", position="dodge")
```

# Accidentalidad por día
```{r}
acc_dian <- acc %>% 
              group_by(DIA_NOMBRE) %>% 
              summarize(total_registros = n())
acc_dian <- acc_dian[with(acc_dian, order(c(names(acc_dian$DIA_NOMBRE)))), ] #
head(acc_dian)
```
head(acc_dian)
view (acc_dian$DIA_NOMBRE)

```{r}
ggplot(data=acc_dian, aes(x=DIA_NOMBRE, y=total_registros)) + 
    geom_bar(stat="identity", position="dodge")
```




# Agrupar Gravedad-Clase
```{r}
acc_group_clase<- acc %>% group_by(GRAVEDAD, CLASE) %>% summarize(conteo = n()) %>% spread(GRAVEDAD, conteo, fill=0)
View(acc_group_clase)
```

```{r}
acc_group_clase1<- acc %>% group_by(GRAVEDAD, CLASE) %>% summarize(conteo = n())

ggplot(data=acc_group_clase1, aes(x=GRAVEDAD, y=conteo, fill=CLASE)) + 
    geom_bar(stat="identity", position="dodge")+
    scale_fill_manual(values=c("#67001f","#b2182b","#d6604d","#f4a582","#fddbc7","#d1e5f0", "#92c5de","#4393c3","#2166ac", "#053061"))
```


# Agrupar Gravedad-Mes
```{r}
acc_group_mes<- acc %>% group_by(GRAVEDAD, MES) %>% summarize(conteo = n()) %>% spread(GRAVEDAD, conteo, fill=0)
head(acc_group_mes)
```
```{r}
acc_group_mes1<- acc %>% group_by(GRAVEDAD, MES) %>% summarize(conteo = n())

ggplot(data=acc_group_mes1, aes(x=GRAVEDAD, y=conteo, fill=MES)) + 
    geom_bar(stat="identity", position="dodge")
```


# Agrupar Gravedad-Periodo
```{r}
#acc_year$PERIODO <- as.numeric(acc_year$PERIODO)
acc_group_year<- acc %>% group_by(GRAVEDAD, PERIODO) %>% summarize(conteo = n()) %>% spread(GRAVEDAD, conteo, fill=0)
head(acc_group_year)
```

# Gráfica Gravedad-Periodo
```{r}
acc_group_year1<- acc %>% group_by(GRAVEDAD, PERIODO) %>% summarize(conteo = n())

 
ggplot(data=acc_group_year1, aes(x=GRAVEDAD, y=conteo, fill=PERIODO)) + 
    geom_bar(stat="identity", position="dodge")+
    scale_fill_manual(values=c("#d0d1e6", "#bdc9e1","#74a9cf","#2b8cbe","#045a8d"))

```

```{r}
acc_group_dia<- acc %>% group_by(GRAVEDAD, DIA_NOMBRE) %>% summarize(conteo = n()) %>% spread(GRAVEDAD, conteo, fill=0)
head(acc_group_dia)
````
```{r}
acc_group_dia1<- acc %>% group_by(GRAVEDAD, DIA_NOMBRE) %>% summarize(conteo = n())

ggplot(data=acc_group_dia1, aes(x=GRAVEDAD, y=conteo, fill=DIA_NOMBRE)) + 
    geom_bar(stat="identity", position="dodge")+
    scale_fill_manual(values=c("#67001f","#b2182b","#d6604d","#f4a582","#fddbc7","#d1e5f0", "#92c5de"))
```

#View(acc_comuna)
# Contar número de accidentes por año
acc_year <- acc %>% 
              group_by(PERIODO) %>% 
              summarize(total_registros = n())
acc_year$PERIODO <- as.numeric(acc_year$PERIODO)
acc_year$total_registros <- as.numeric(acc_year$total_registros)
View(acc_year)

summary(acc_year)

plot_ly (data = acc_year,
         x = ~PERIODO,
         y = ~total_registros,
         type = "scatter",
         mode = "lines",
         line = list(width = 1, color = 'rgb(205, 12, 24)')) %>%
  layout(title = 'Registros de la accidentalidad en Medellín',
         xaxis = list(title="Comuna"),
         yaxis = list(title="Registros"))
# crear grafico por comuna
```{r}
plot_ly (data = acc_comuna,
         x = ~COMUNA,
         y = ~total_registros,
         type = "scatter",
         mode = "lines",
         line = list(width = 1, color = 'rgb(205, 12, 24)')) %>%
  layout(title = 'Registros de la accidentalidad en Medellín',
         xaxis = list(title="Comuna"),
         yaxis = list(title="Registros"))
```



# Scaterplot Ubicacion```
```{r}
plot(acc$X, acc$Y, main="Scatterplot Ubicación")
```

plot(acc$X, acc$Y, main="Scatterplot Ubicación")
   
   
[Regresar](#tabla-de-contenido)

#### **2.3.3. Datos atípicos o nulos**

**FALTA**


[Regresar](#tabla-de-contenido)

### **2.4. Modelación de los datos**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.5. Evaluación del modelo**

**FALTA**

[Regresar](#tabla-de-contenido)

### **2.6. Implementación**

**FALTA**

[Regresar](#tabla-de-contenido)

## **3. Conclusiones**

**FALTA**

[Regresar](#tabla-de-contenido)

## **4. Bibliografía**

**FALTA**

**R Markdown**

+ [Infografía de *Rmarkdown*](https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf)

+ [API de *Rmarkdown*](https://bookdown.org/yihui/rmarkdown/)

---

**Plotly**

+ [API de *Plotly*](https://plot.ly/r/reference/)

---

**Shiny**

+ [API de *Shiny*](http://shiny.rstudio.com/articles/basics.html)

+ [Incrustar videos en *Shiny*](https://stackoverflow.com/questions/43740470/embed-instagram-youtube-into-shiny-r-app)

+ [Rango de fechas en *Shiny*](https://shiny.rstudio.com/gallery/date-and-date-range.html)

+ [Pestañas en *Shiny*](https://shiny.rstudio.com/articles/tabsets.html)

+ [Incrustar HTML y Markdown en *Shiny*](http://shiny.rstudio.com/gallery/including-html-text-and-markdown-files.html)

---

**Demás**

+ [link aquí](https://wikipedia.com)

---

[Regresar](#tabla-de-contenido)
